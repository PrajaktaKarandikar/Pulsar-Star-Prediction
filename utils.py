# -*- coding: utf-8 -*-
"""utils (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Sm1hriLCHoMw-Nf3Vu0w96rd4imuDQ2p
"""

from google.colab import drive
drive.mount('/content/drive')

import os, random, shutil
import csv
import math
import numpy as np 
import pandas as pd 
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, auc, confusion_matrix
from sklearn.metrics import roc_auc_score, f1_score, roc_curve, mean_absolute_error, mean_squared_error
import warnings
warnings.filterwarnings("ignore")

#set seed
np.random.seed(30)

PROJ_DIR = '//'.join(os.path.dirname("/content/drive/MyDrive/EE660_Proj/").split("/"))
DATA_DIR = '//'.join(os.path.dirname("/content/drive/MyDrive/EE660_Proj/Data").split("/"))

def calculate_metrics(y1, ypred):
  """
  Computes Accuracy, Mean Squared Error, Root Mean Squared Error, Mean Absolute Error, ROC-AUC Score and Classification Report.
  """
  acc = round((accuracy_score(y1, ypred))*100, 4)
  mae = round((mean_absolute_error(y1, ypred))*100, 4)
  mse = round((mean_squared_error(y1, ypred))*100, 4)
  rmse = round((math.sqrt(mse))*100, 4)
  auc_score = round((roc_auc_score(y1, ypred))*100, 4)
  class_report = classification_report(y1, ypred, output_dict=True)

  return acc, mae, mse, rmse, auc_score, class_report

def print_results(acc, mae, mse, rmse, auc_score, class_report):
  """
  Prints the results obtained.
  """
  print("Accuracy: %s" %acc), '%'
  print('Mean Absolute Error: %s' %mae), '%'
  print('Mean Squred Error: %s' %mse), '%'
  print('Root Mean Squared Error: %s' %rmse), '%'
  print('ROC-AUC score: %s' %auc_score), '%', '\n'
  print(class_report)

def save_results_tocsv(filename, ds, cols):
  model_dict = {}
  for k in ds[0].keys():
    model_dict[k] = tuple(model_dict[k] for model_dict in ds)

  with open((os.path.join(PROJ_DIR, filename)), 'w') as f:
    writer = csv.writer(f)
    for key, value in model_dict.items():
      writer.writerow([key, value])

def class_report_csv(report, mod_name):
 class_report = pd.DataFrame(report).transpose()
 class_report.to_csv(os.path.join(PROJ_DIR, "Classification_Report_{}.csv".format(mod_name)), index = False, header=True)

def plot_confusion_mat(conf_mat, name, title):
  """
        Plots confusion matrix.
  """
  plt.clf()
  plt.figure(figsize = (8,4))
  sns.set(font_scale=1.2)
  groups = ['TrueNegative', 'FalsePostive', 'FalseNegative', 'TruePositive']
  counts = ["{0:0.0f}".format(value) for value in conf_mat.flatten()]
  classLabels= ['Not Pulsar ', 'Pulsar']
  labels2 = [f"{v1}\n{v2}".strip() for v1, v2 in zip(groups, counts)]
  labels2 = np.array(labels2).reshape(2,2)
  sns.heatmap(conf_mat, cmap="Blues", annot=labels2, fmt = '', xticklabels=classLabels, yticklabels=classLabels)
  plt.title(title, fontsize =  15)
  plt.xlabel('Predicted class', fontsize = 13)
  plt.ylabel('True class', fontsize = 13)
  plt.grid(False)
  plt.savefig(os.path.join(PROJ_DIR, "ConfusionMatrix_{}.png" .format(name)), bbox_inches="tight", dpi= 200)
  plt.show()
  

def plot_roc_curve(name, ytest, prediction):  
  """
        Plots ROC curve.
  """
  plt.style.use('seaborn') 
  plt.clf()
  fpr, tpr, thresh = roc_curve(ytest, prediction)
  auc_score = round(auc(fpr, tpr), 4)
  plt.figure(num=None, figsize=(6, 5))
  plt.plot(fpr, tpr, color="darkorange", label=('ROC Curve (Area  = {})'.format(auc_score)))
  plt.grid(False)
  plt.plot([0, 1], [0, 1], linestyle = "dashed", color="navy")
  plt.xlim([0.0, 1.0])
  plt.ylim([0.0, 1.0])
  plt.title('Receiver Operating Characteristic (ROC) Curve', verticalalignment="bottom", fontsize=14)
  plt.xlabel('False Positive Rate', fontsize=13)
  plt.ylabel('True Positive Rate', fontsize=13)
  plt.legend(loc='lower right', fontsize=12, frameon = True)
  plt.savefig(os.path.join(PROJ_DIR, 'ROC_finalModel_%s' %name + ".png"), bbox_inches="tight", dpi=400)
  plt.show()