# -*- coding: utf-8 -*-
"""modules.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WiHaOk11A2aJrVQniA7XZQCi9IHg0oL0

# New Section
"""

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files
files.upload()

import sys
sys.path.insert(0,'/content/drive/MyDrive/Colab Notebooks/utils.py')

import csv, os
import pickle
import numpy as np 
import pandas as pd 
import seaborn as sns
from scipy.io import arff
import os, random, shutil
import matplotlib.pyplot as plt
from collections import Counter
#from sklearn.decomposition import PCA
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix, mean_squared_error, mean_absolute_error
from sklearn.pipeline import Pipeline
#from sklearn.model_selection import KFold
#import EDAandPreprocessing

import warnings
warnings.filterwarnings("ignore")

#from utils import class_report_csv
#from utils import read_data, plot_confusion_mat, plot_roc_curve, print_results, calculate_metrics
#from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, plot_confusion_matrix
import utils
import importlib
importlib.reload(utils)

#set seed
np.random.seed(30)

PROJ_DIR = '//'.join(os.path.dirname("/content/drive/MyDrive/EE660_Proj/").split("/"))
DATA_DIR = '//'.join(os.path.dirname("/content/drive/MyDrive/EE660_Proj/Data").split("/"))

#dir_path = os.path.dirname(os.path.realpath("/content/drive/MyDrive/Colab Notebooks/"))
train = pd.read_csv("/content/drive/MyDrive/EE660_Proj/training_data.csv")
val = pd.read_csv("/content/drive/MyDrive/EE660_Proj/validation_data.csv")
test = pd.read_csv("/content/drive/MyDrive/EE660_Proj/test_data.csv")
X_train = train.iloc[:, 0:8]
y_train = train.iloc[:, -1]
X_val = val.iloc[:, 0:8]
y_val = val.iloc[:, -1]
X_test = test.iloc[:, 0:8]
y_test = test.iloc[:, -1]

X_train.isnull().sum()

best_params = {}
best_estimators = {}
train_scores = {}
val_scores = {}
auc_scores = {}

class find_best_params():
    # Find the best parameters
       
    def train_and_validate(mod_name, md,  param_grid, Xtr, ytr, X_v, y_v):
      print(mod_name)
      clfr_grid = GridSearchCV(md, param_grid= param_grid[mod_name], cv = 5, verbose=True, n_jobs=-1)
      best_clfr = clfr_grid.fit(Xtr, ytr)
      est = best_clfr.best_estimator_
      best_estimators[mod_name] = est
      best_params[mod_name] = best_clfr.best_params_
      train_scores[mod_name] = best_clfr.best_score_

      print("Best Training Accuracy: %s" %best_clfr.best_score_), '%'
      est.fit(Xtr, ytr)
      y_pred = est.predict(X_v)
      v_acc, mae, mse, rmse, auc_score, class_report = utils.calculate_metrics(y_v, y_pred)
      val_scores[mod_name] = v_acc
      auc_scores[mod_name] = auc_score 

      print("Validation Results: "), '%', 'n'
      utils.print_results(v_acc, mae, mse, rmse, auc_score, class_report)
      cm = confusion_matrix(y_v, y_pred)
      utils.plot_confusion_mat(cm, mod_name, "Confusion Matrix of Model: {}".format(mod_name))
      utils.class_report_csv(class_report, mod_name)
      
      return best_estimators, best_params, train_scores, val_scores, auc_scores
      #print(confusion_matrix(yval, y_pred))

class find_best_model():
  def get_best_model(Xtr, ytr, Xval, yval):
    models_params = {
        'Logistic Regression': [
                               {'penalty': ['l2', 'l1', 'elasticnet', 'none']},
                               {'tol': [1e-4, 1e-3, 1e-5, 1e-7]},
                               {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, 
                               {'fit_intercept' : ['True', 'False']},
                               {'class_weight' : [None, 'balanced']},
                              {'solver' : ['liblinear', 'saga', 'newton-cg', 'lbfgs', 'sag']},
                              {'max_iter' : np.logspace(1, 4, 4)}
        ],
      
        'Naive Bayes': [
                        {'priors' : [[0.67, 0.33], [0.5, 0.5], [0.25, 0.75], [0.75, 0.25], [0.33, 0.67]]},
                        {'var_smoothing': [1e-3, 1e-4, 1e-5, 1e-7, 1e-9]}
        ],
      
        'SVM': [
                {'kernel': ['rbf', 'sigmoid', 'linear']}, 
                {'gamma': ['scale', 'auto']},
                {'C': [0.001, 0.10, 0.1, 10, 100, 1000]},
                {'class_weight' : [None, 'balanced']},
                {'max_iter' : np.logspace(1, 4, 4)},
                {'decision_function_shape' : ['ovo', 'ovr']}
        ],
      
        'KNN': [
                {'n_neighbors': np.linspace(3, 51, 24, dtype=np.int16)},
                {'weights': ['uniform', 'distance']},
                {'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']},
                {'leaf_size' : [10, 15, 30, 45, 60]},
                {'n_jobs': [-1, 1, 2, 3, 4, 5]}
        ],
      
        'Decision Tree': [
                          {'criterion' : ['gini', 'entropy']},
                          {'splitter' : ['random', 'best']},
                          {'max_depth': list(np.logspace(0, 6, 5))},
                          {'min_samples_split': np.linspace(2, 100, 5, dtype=np.int16)},
                          {'min_samples_leaf': np.linspace(1, 100, 5, dtype=np.int16)},
                          {'max_features' : ['auto', 'sqrt', 'log2']},
                          {'min_impurity_decrease' : np.linspace(0, 1, 5)},
                          {'class_weight' : [None, 'balanced']},
                          {'ccp_alpha' : np.linspace(0, 1 ,5)}
        ],
      
        'Random Forest': [
                          {'n_estimators': [100, 1000, 5000, 10000]},
                          {'criterion' : ['gini', 'entropy']},
                          {'max_depth': list(np.logspace(0,6,5))},
                          {'min_samples_split':  np.linspace(2, 100, 5, dtype=np.int16)},
                          {'min_samples_leaf':  np.linspace(1, 100, 5, dtype=np.int16)},
                          {'max_features' : ['auto', 'sqrt', 'log2']},     
                          {'class_weight' : [None, 'balanced']},
                          {'bootstrap' : ['True','False']},
                          {'oob_score' : ['True','False']}
        ],
      
        'AdaBoost': [
                     {'base_estimator' : [('lr', LogisticRegression()), 
                                                          ('dt', DecisionTreeClassifier()),
                                                          ('rf', RandomForestClassifier())]},
                     {'n_estimators' : [100, 500, 1000, 5000, 10000]},
                     {'learning_rate' : [0.01, 0.05, 0.09, 0.5, 0.9]},
                     {'algorithm' : ['SAMM', 'SAMME.R']},
        ],
      
        'Voting Classifier': [
                              {'voting': ['hard', 'soft']}    
        ]
    }
    
    models = {
        'Logistic Regression': LogisticRegression(n_jobs=-1, random_state=30),
        'Naive Bayes': GaussianNB(),
        'SVM': SVC(probability=True, random_state=30),
        'KNN': KNeighborsClassifier(),
        'Decision Tree': DecisionTreeClassifier(random_state=30),
        'Random Forest': RandomForestClassifier(random_state=30),
        'AdaBoost': AdaBoostClassifier(random_state = 30),
        'Voting Classifier': VotingClassifier(estimators = [('lr', LogisticRegression()), 
                                                                                                       ('dt', DecisionTreeClassifier()),
                                                                                                       ('rf', RandomForestClassifier()),
                                                                                                       ('ab', AdaBoostClassifier())])
    }
    
    for model_name, mod_dat in models.items():
      best_estimators, best_params, train_scores, val_scores, auc_scores = find_best_params.train_and_validate(model_name, mod_dat, models_params, Xtr, ytr, Xval, yval )
    
    # save results
    ds1 = [models, models_params]
    csv_cols1 = ['Model Name', 'Model Parameter Choices']
    ds2 = [best_estimators, best_params, train_scores, val_scores, auc_scores]
    csv_cols2 = ['Model Name','Best Estimator','Best Parameters', 'Best Training Accuracy', 'Best Validation Accuracy', 'Roc-AUC Scores']
    
    utils.save_results_tocsv("Model_Parameter_Choice.csv", ds1, csv_cols1)
    utils.save_results_tocsv("Training&Validation_Results.csv", ds2, csv_cols2)

    best = 0
    name = " "
    for (model_name, scores) in val_scores.items(): 
      if scores > best:
        best = scores
        name = model_name
    print("Best Model: {}".format(name))

    #save best model   
    with open("BestModel.pickle", "wb") as f:
      pickle.dump(best_estimators[name], f)
  
    return name, best_estimators[name], best_estimators, best_params, train_scores, val_scores, auc_scores, models, models_params

  #Running the final chosen model on test data
  def run_test(mod_name, estim, Xtr, ytr, Xtest, ytest):
    best_model = estim.fit(Xtr, ytr)
    y_pred = best_model.predict(Xtest)
    pred_prob = best_model.predict_proba(Xtest)
    #print(pred_prob.shape)
    t_acc, mae, mse, rmse, auc_score, class_report = utils.calculate_metrics(ytest, y_pred)
    print("Test Results: ")
    utils.print_results(t_acc, mae, mse, rmse, auc_score, class_report)
    cm = confusion_matrix(ytest, y_pred)
    utils.plot_confusion_mat(cm, mod_name, "Confusion Matrix of Model: {}".format(mod_name))
    utils.plot_roc_curve(mod_name, ytest, pred_prob[:, 1])

#training and validation
model_name, mod_estim, best_estimators, best_params, train_scores, val_scores, auc_scores, models, models_params = find_best_model.get_best_model(X_train, y_train, X_val, y_val)

#run test on final best model
find_best_model.run_test(model_name, mod_estim, X_train, y_train, X_test, y_test)